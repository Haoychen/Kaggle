help(subset)
1 : 4
1: 4
help(mean)
help(cat)
rep(1, 10)
Diabets <- c('Type1', 'Type2')
factor(Diabets)
install.packages(ISLR)
install.packages(MASS)
install.packages(ISLR)
install.packages(ISLR)
install.packages('ISLR')
par(mfrow = c(2, 2))
slices <- c(10, 12, 4, 16, 8)
lbls <- c('US', 'UK', 'Australia', 'Germany', 'France')
pie(slices, labels = lbls, main = "Simple Pie Chart")
pct <- round(slices / sum(slices) * 100)
lbls2 <- paste(lbls, ' ', pct, "%", sep = '')
lbls2
pie(slices, labels = lbls2, col = rainbow(length(lbls2)), main = "Pie Chart with Percentage")
library(plotrix)
pie3D(slices, labels = lbls, explode = 0.1, main = "3D Pie Chart")
mytable <- table(state.region)
mytable
lbls3 <- paste(names(mytable), '\n', mytable, sep = '')
pie(mytable, labels = lbls3, main = "Pie Chart from a Table\n (with sample sizes")
help(hist)
par(mfrow = c(2, 2))
hist{(mtcars$mpg)}
hist(mtcars$mpg)
hist(mtcars$mpg, breaks = 12, col = 'red')
hist(mtcars$mpg, breaks = 12, col = 'red')
rug(jitter(mtcars$mpg))
lines(density(mtcars$mpg), col = 'blue', lwd = 2)
x <- mtcars$mpg
h <- hist(x, breaks = 12, col = 'red')
xfit <- seq(min(x), max(x), length = 40)
yfit <- dnorm(xfit, mean = mean(x), sd = sd(x))
yfit <- yfit * diff(h$mids[1: 2]) * length(x)
lines(xfit, yfit, col = 'blue', lwd = 2)
box()
h&minds
h$mids
help(diff)
d <- density(mtcars$mpg)
polygon(d, col = 'red', border = 'blue')
plot(d)
polygon(d, col = 'red', border = 'blue')
help(polygon)
install('sm')
install.packages('sm')
par()
par(mfrow = c(1, 1))
library(sm)
attach(mtcars)
cyl.f <- factor(cyl, levels = c(4, 6, 8), labels = c('4 cylinder', '6 cylinder', '8 cylinder'))
sm.density.compare(mpg, cyl)
sm.density.compare(mpg, cyl.f)
cyl
sm.density.compare(mpg, cyl.f)
cyl
sm.density.compare(mpg, cyl)
par(mfrow = c(1, 1))
library(sm)
attach(mtcars)
cyl.f <- factor(cyl, levels = c(4, 6, 8), labels = c('4 cylinder', '6 cylinder', '8 cylinder'))
sm.density.compare(mpg, cyl)
colfill <- c(2: (1 + length(levels(cyl.f))))
legend(locator(1), levels(cyl.f), fill = colfill)
cyl.f
box(mpg ~ cyl, data = mtcars, notch = TRUE, varwidth = TRUE)
boxplot(mpg ~ cyl, data = mtcars, notch = TRUE, varwidth = TRUE)
install.packages('vioplot')
library(vioplot)
within(mtcars,{
x1 <- mpg[cyl == 4]
x2 <- mpg[cyl == 6]
x3 <- mpg[cyl == 8]
})
with(mtcars,{
x1 <<- mpg[cyl == 4]
x2 <<- mpg[cyl == 6]
x3 <<- mpg[cyl == 8]
})
within(mtcars,{
x1 <- mpg[cyl == 4]
x2 <- mpg[cyl == 6]
x3 <- mpg[cyl == 8]
})
vioplot(x1, x2, x3)
library(Hmisc)
myvars <- c('mpg', 'hp', 'wt')
describe(mtcars[myvars])
install.packages('pastecs')
library(pastecs)
myvar <- c('mpg', 'hp', 'wt')
stat.desc(mtcars[myvar])
install.packages('psych')
install.packages('doBy')
library(vcd)
install.packages('vcd')
install.packages("vcd")
library(vcd)
head(Arthritis)
install.packages('gmodels')
help(addmargins)
t_value <- 2.142884
2 * pt(t_value, 43)
2 * (1 - pt(t_value, 43))
qt(0.975, 43)
t_value <- 2.1429
pt(t_value, 43)
y <- c(40, 41, 43, 42, 44, 42, 43, 42)
x <- c(0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0)
m1 <- lm(y ~ x)
summary(m1)
anova(m1)
x_bar <- mean(x)
x_bar
ssx <- sum((x - x_bar) ** 2)
ssx
1.2877 / 10.5
sqrt(0.122638)
0.8842 * 0.8842
10.5 * 10.5
1.2877 * (1 / 8 + 110.25 / 10.5)
2.25 ** 2
1.2877 * (1 / 8 + 5.0625 / 10.5)
x <- c(0.3, 1.4, 1.0, -0.3, -0.2, 1.0, 2.0, -1.0, -0.7, 0.7)
y <- c(0.4, 0.9, 0.4, -0.3, 0.3, 0.8, 0.7, -0.4, -0.2, 0.7)
m1 <- lm(y ~ x)
summary(m1)
setwd("~/Coding/R")
census.data <- read.table("census.csv", header = T)
head(census.data)
census.data <- read.csv("census.csv", header = T)
head(census.data)
census.sample <- census.data[is.na(census.data) == FALSE]
head(census.sample)
census.sample <- census.data[is.na(census.data$outcome) == FALSE,]
head(census.sample)
census.prediction <- census.data[is.na(census.data$outcome) == TRUE,]
head(census.prediction)
census.data <- read.csv("census.csv", header = T)
with(census.data, {
educ <<- factor(educ)
status <<- factor(status)
race <<- factor(race)
gender <<- factor(gender)
})
census.sample <- census.data[is.na(census.data$outcome) == FALSE,]
census.prediction <- census.data[is.na(census.data$outcome) == TRUE,]
head(census.sample)
character(census.data$educ)
character(census.data$age)
help(character)
is.factor(census.data$educ)
logistic.fit = glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
summary(logistic.fit)
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
summary(logistic.fit)
library(ISLR)
set.seed(1)
library(boot)
cv.err <- cv.glm(census.sample, logistic.fit)
dim(census.sample)
library(MASS)
help(qda)
qda.fit <- qda(outcome ~ age + educ + status + race + gender + hrs, data = census.sample)
summary(qda.fit)
predict(qda, newdata = data.frame(age = 10, educ = 'Bachelor', Status = 'Divorced', race = 'white', gender = 'Female'))
head(census.sample)
predict(qda, newdata = census.sample[1, 1 - 7], gender = 'Female'))
predict(qda, newdata = census.sample[1, c(1-7)], gender = 'Female'))
predict(qda, newdata = census.sample[1, c(1, 2, 3, 4, 5, 6)], gender = 'Female'))
predict(qda, newdata = census.sample[1, c(1, 2, 3, 4, 5, 6)])
predict(qda, newdata = census.sample[1, 1 : 6])
predict(qda, census.sample[1, 1 : 6])
predict(qda, census.sample[, 1:6])
predict(qda.fit, census.sample[, 1:6])
predict(qda.fit, census.sample[1, 1:6])
predict(qda.fit, census.sample[1:2, 1:6])
qda.class <- predict(qda.fit, census.sample[, 1:6])$class
table(qda.class, census.sample[, 7])
mean(qda.calss == census.sample[, 7])
mean(qda.class == census.sample[, 7])
logistic.fit <- predict(logistic.fit, census.sample[, 1:6])$class
predict(logistic.fit, census.sample[, 1:6])
predict(logistic.fit, census.sample[1, 1:6])
predict(logistic.fit, census.sample[1:2, 1:6])
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
predict(logistic.fit, census.sample[1:2, 1:6])
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = "binomial")
predict(logistic.fit, census.sample[1:2, 1:6])
predict(logistic.fit, census.sample[1:10, 1:6])
predict(logistic.fit, census.sample[1:10, 1:6], type = 'response')
logistic.value <- predict(logistic.fit, census.sample[, 1:6], type = 'response')
mean(logistic.value)
logistic.value[logistic.value >= .5] = 1
logistic.value[logistic.value < .5] = 0
table(logistic.value, census.sample[, 7])
mean(logistic.value == census.sample[, 7])
step(logistic.fit, direction = "both")
step(logistic.fit, direction = "backward")
logistic.value <- predict(logistic.fit, census.prediction[, 1:6])
head(logistic.value)
logistic.value <- predict(logistic.fit, census.prediction[, 1:6], type = "response")
head(logistic.value)
logistic.value[logistic.value > .5] <- 1
logistic.value[logistic.value < .5] <- 0
head(logistic.value)
dim(logistic.value)
census.prediction$outcome <- logistic.value
output.data <- rbind(census.sample[, 7: 8], census.prediction[, 7: 8])
head(output.data)
output.data <- output.data[, c('id', 'outcome')]
head(output.data)
output.data <- output.data[order(output.data$id),]
head(output.data)
View(output.data)
predict(qda.fit, census.prediction[,1: 6])$class
predict(qda.fit, census.prediction[1,1: 6])$class
head(census.prediction)
predict(qda.fit, census.prediction[2,1: 6])$class
predict(qda.fit, census.prediction[3,1: 6])$class
predict(qda.fit, census.prediction[1:6,1: 6])$class
write.table(output.data, "hw5.txt")
write.table(output.data, "hw5.txt", sep = '\t')
View(output.data)
write.table(output.data, "hw5.txt", sep = '\t')
help(write.table)
dim(output.data)
write.table(output.data, "hw5.txt", sep = '\t')
write.table(output.data, "hw5.txt", col.names = c("id", "outcome"), row.names = output.data[,1] sep = '\t')
write.table(output.data, "hw5.txt", col.names = c("id", "outcome"), row.names = output.data[,1], sep = '\t')
write.table(output.data, "hw5.csv")
write.table(output.data, "hw5.csv", sep = '\t')
View(output.data)
write.csv(output.data, "hw5.csv")
input.data <- read.table("hw5.txt", header = T)
head(input.data)
View(census.data)
View(census.prediction)
census.data <- read.csv("census.csv", header = T)
with(census.data, {
educ <<- factor(educ)
status <<- factor(status)
race <<- factor(race)
gender <<- factor(gender)
})
census.sample <- census.data[is.na(census.data$outcome) == FALSE,]
census.prediction <- census.data[is.na(census.data$outcome) == TRUE,]
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
logistic.value <- predict(logistic.fit, census.prediction[, 1:6], type = 'response')
logistic.value[logistic.value > .5] <- 1
logistic.value[logistic.value < .5] <- 0
output.data <- cbind(logistic.value, census.prediction[,8])
View(output.data)
write.table(logistc.value, 'output.txt', sep = '\t')
write.table(logistic.value, 'output.txt', sep = '\t')
write.table(logistic.value, 'output.txt', sep = '\t', colname = c('id', 'outcome'))
write.table(output.data, 'output.txt', sep = '\t')
output <- output[,c(2,1)]
output.data <- output.data[,c(2,1)]
write.table(output.data, 'output.txt', sep = '\t')
dim(output.data)
names(output.data) <- c('id', 'outcome')
write.table(output.data, 'output.txt', sep = '\t')
write.table(output.data, 'output.txt', sep = '\t')
library(FSelector)
setwd("~/Project/Kaggle/London + Scikit")
print weights
print(weights)
library(e1071)
library(FSelect)
#read training data
train_features.data <- read.csv('new_data.csv',header = FALSE)
train_response.data <- read.csv('trainLabels.csv',header = FALSE)
train.data <- cbind(train_features.data, train_response.data)
train_features.data <- read.csv('new_data.csv',header = FALSE)
train_features.data <- read.csv('train.csv',header = FALSE)
train_response.data <- read.csv('trainLabels.csv',header = FALSE)
train.data <- cbind(train_features.data, train_response.data)
weights <- random.forest.importance(train_respone.data ~ ., train.data, importance.type = 1)
print(weights)
library(FSelect)
library(FSelect)
??random.forest.importance
library(FSelector)
weights <- random.forest.importance(train_respone.data ~ ., train.data, importance.type = 1)
print(weights)
View(train.data)
weights <- random.forest.importance(response ~ ., train.data, importance.type = 1)
train_features.data <- read.csv('train.csv',header = FALSE)
train_response.data <- read.csv('trainLabels.csv',header = FALSE, col.name = 'response')
train.data <- cbind(train_features.data, train_response.data)
View(train.data)
weights <- random.forest.importance(response ~ ., train.data, importance.type = 1)
weights
weights[order(weights$attr_importance),]
sort(weights)
feature_index <- c(1:40)
weights <- cbind(weights, feature_index)
weights[order(weights$attr_importance, decreasing = TRUE),]
cost_list <- c(0.01, 0.1, 1, 2.7, 10, 100, 150, 200, 250, 300, 350)
gamma_list <- c(0.0001, 0.0005, 0.0007, 0,001, 0.01, 0.09, 0.015, 0.02, 0.025, 0.03, 0.1, 1)
for(i in cost_list) {
for(j in gamma_list){
set.seed(10)
model <- svm(train.data$result.data ~ ., data = train.data, kernel = 'radial',gamma = j, cost = i, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(i, j, accuracy)
print(observation)
}
}
cost_list <- c(0.01, 0.1, 1, 2.7, 10, 100, 150, 200, 250, 300, 350)
gamma_list <- c(0.0001, 0.0005, 0.0007, 0,001, 0.01, 0.09, 0.015, 0.02, 0.025, 0.03, 0.1, 1)
for(i in cost_list) {
for(j in gamma_list){
set.seed(10)
model <- svm(response ~ ., data = train.data, kernel = 'radial',gamma = j, cost = i, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(i, j, accuracy)
print(observation)
}
}
model <- svm(response ~ ., data = train.data, kernel = 'radial',gamma = j, cost = i, cross = 10)
accuracy <- summary(model)$tot.accuracy
str(train.data)
train.data$response <- as.factor(train.data$response)
train_filter.data <- train.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
cost_list <- c(0.01, 0.1, 1, 2.7, 10, 100, 150, 200, 250, 300, 350)
gamma_list <- c(0.0001, 0.0005, 0.0007, 0,001, 0.01, 0.09, 0.015, 0.02, 0.025, 0.03, 0.1, 1)
for(i in cost_list) {
for(j in gamma_list){
set.seed(10)
model <- svm(response ~ ., data = train_filter.data, kernel = 'radial',gamma = j, cost = i, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(i, j, accuracy)
print(observation)
}
}
train_filter.data <- train.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39,41)]
cost_list <- c(0.01, 0.1, 1, 2.7, 10, 100, 150, 200, 250, 300, 350)
gamma_list <- c(0.0001, 0.0005, 0.0007, 0,001, 0.01, 0.09, 0.015, 0.02, 0.025, 0.03, 0.1, 1)
for(i in cost_list) {
for(j in gamma_list){
set.seed(10)
model <- svm(response ~ ., data = train_filter.data, kernel = 'radial',gamma = j, cost = i, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(i, j, accuracy)
print(observation)
}
}
train_PCA.data <- prcomp(train_filter.data[, -41], scale = TRUE)
train_PCA.data <- prcomp(train_filter.data[, c(-41)], scale = TRUE)
str(train_filter.data[, -41])
train_PCA.data <- prcomp(train_filter.data[, c(-16)], scale = TRUE)
train_PCA.data <- prcomp(train_filter.data[, c(-16)], scale = TRUE)$x
View(train_PCA.data)
dim(train_PCA.data)
train_PCA.data <- data.frame(prcomp(train_filter.data[, c(-16)], scale = TRUE)$x)
train_PCA.data <- cbind(train_PCA.data, train_response.data)
train_PCA.data$response <- as.factor(train_PCA.data$response)
train_PCA.data <- data.frame(prcomp(train_filter.data[, c(-16)], scale = TRUE)$x)
train_PCA.data <- cbind(train_PCA.data, train_response.data)
train_PCA.data$response <- as.factor(train_PCA.data$response)
pc_num <- c(1:15)
for(k in pc_num) {
set.seed(10)
model <- svm(response ~ ., data = train_PCA.data[, c(1:k, 16)], kernel = 'radial',gamma = 0.09, cost = 2.7, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(1, 0.03, k, accuracy)
print(observation)
}
pc_num <- c(1:15)
for(k in pc_num) {
set.seed(100)
model <- svm(response ~ ., data = train_PCA.data[, c(1:k, 16)], kernel = 'radial',gamma = 0.09, cost = 2.7, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(1, 0.03, k, accuracy)
print(observation)
}
model <- svm(response ~ ., data = train_PCA.data[, c(1:13, 16)], kernal = 'linear', gamma = 0.09, cost = 2.7, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(1, 0.03, k, accuracy)
print(observation)
set.seed(10)
model <- svm(response ~ ., data = train_PCA.data[, c(1:13, 16)], kernal = 'linear', gamma = 0.09, cost = 2.7, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(1, 0.03, k, accuracy)
print(observation)
set.seed(10)
model <- svm(response ~ ., data = train_PCA.data[, c(1:13, 16)], kernal = 'radial', gamma = 0.09, cost = 2.7, cross = 10)
accuracy <- summary(model)$tot.accuracy
observation <- c(1, 0.03, k, accuracy)
print(observation)
test_feature.data <- read.csv('test.csv', header = FALSE)
test_feature.data <- test_feature.data[,c(c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)
test_feature.data <- test_feature.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)
test_response.data <- predict(model, newdata = test_PCA.data)
View(train_response.data)
test_ID <- c(1:9000)
test.data <- cbind(test_ID, test_response.data, col.name = c('Id', 'Solution'))
View(test.data)
test.data <- cbind(test_ID, test_response.data)
names(test.data) <- c('Id', 'Solution')
View(test.data)
names(test.data)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
View(test.data)
test.data <- data.frame(cbind(test_ID, test_response.data), col.name = c('Id', 'Solution'))
View(test.data)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
View(test.data)
write.csv(test.data)
write.csv(test.data)
write.csv(test.data, file = 'solution')
write.table(test.data, file = 'solution.csv')
write.csv(test.data, file = 'solution.csv')
solution <- read.csv('solution.csv')
View(solution)
View(test.data)
View(train_response.data)
test_feature.data <- read.csv('test.csv', header = FALSE)
#Manipulate the test features
test_feature.data <- test_feature.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)
test_response.data <- predict(model, newdata = test_PCA.data)
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
write.csv(test.data, file = 'solution.csv')
View(train_response.data)
View(test.data)
help(predict)
str(train_PCA.data)
View(train_response.data)
str(test_response.data)
test_response.data <- test_response.data - 1
View(train_response.data)
test_response.data <- as.integer(test_response.data)
test_response.data <- test_response.data - 1
View(test.data)
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
View(test.data)
test_response.data <- levels(test_response.data)
test_response.data <- predict(model, newdata = test_PCA.data)
levels<-.factor(test_response.data)
levels<-.factor
?.factor
?levels
levels(test_response.data)
test_response.data <- as.integer(as.character(test_response.data))
test_response.data <- predict(model, newdata = test_PCA.data)
test_response.data <- as.integer(as.character(test_response.data))
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
View(test.data)
names(test.data) <- c('Id', 'Solution')
write.csv(test.data, file = 'solution.csv')
#Read test data
test_feature.data <- read.csv('test.csv', header = FALSE)
#Manipulate the test features
test_feature.data <- test_feature.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)
test_response.data <- predict(model, newdata = test_PCA.data)
test_response.data <- as.integer(as.character(test_response.data))
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
write.csv(test.data, file = 'solution.csv')
model_2 <-svm(response ~ ., data = train_filter.data, kernal = 'radial', gamma = 0.09, cost = 2.7, cross = 10)
model_2 <-svm(response ~ ., data = train_filter.data, kernal = 'radial', gamma = 0.09, cost = 2.7, cross = 10)
test_feature.data <- test_feature.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)[,c(1:13)]
test_response.data <- predict(model, newdata = test_PCA.data)
test_response.data <- as.integer(as.character(test_response.data))
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
write.csv(test.data, file = 'solution1.csv')
#Read test data
test_feature.data <- read.csv('test.csv', header = FALSE)
#Manipulate the test features
test_feature.data <- test_feature.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)[,c(1:13)]
test_response.data <- predict(model, newdata = test_PCA.data)
test_response.data <- as.integer(as.character(test_response.data))
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
write.csv(test.data, file = 'solution1.csv')
#Read test data
test_feature.data <- read.csv('test.csv', header = FALSE)
#Manipulate the test features
test_feature.data <- test_feature.data[,c(15,13,40,37,19,7,30,5,33,29,35,24,8,23,39)]
test_PCA.data <- data.frame(prcomp(test_feature.data, scale = TRUE)$x)[,c(1:13)]
test_response.data <- predict(model, newdata = test_PCA.data)
test_response.data <- as.integer(as.character(test_response.data))
test_ID <- c(1:9000)
test.data <- data.frame(cbind(test_ID, test_response.data))
names(test.data) <- c('Id', 'Solution')
write.csv(test.data, file = 'solution.csv')
